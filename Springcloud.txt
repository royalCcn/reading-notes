问题：
1.分布式系统中集群时的数据一致性协议raft
	保证集群中的每个节点的数据同步/一致性（简单说：数据同步）
	
	raft协议算法：
		1.状态：
			跟随者、竞选者、领导者
		2.大多数：
			n > n/2 + 1
		3.任期：每次选择一个新的角色
		4.谁的票数大谁就是领导者
		注意：任何算法来源于生活
		
		选择过程：
			1.初始化都为跟随者
			2.系统随机给每个节点超时等待时间
			3.在超时时间过后，状态改为竞选者。在优先度过了超时时间的节点可优先向其他节点发送竞选请求到领导者
			
		核心原理：
			哪个节点的超时时间短，哪个大概率为领导角色
			
		情况：
			1.如果所有节点的超时随机数一样，当前投票作废，重新进入随机生成超时时间
			2.如果有多个节点生成的随机数一样，比较谁的票数多，谁就是领导
			  如果票数完全一样，直接作废，重新进入随机生成超时时间
			建议集群节点为奇数
			
		故障重新选举：
			1.如果跟随者不能及时接收领导者的通知消息，那么跟随者状态就会变为竞选者状态，发给其他节点进行竞选通知，只有
			  该竞选者超过半数以上即可选择领导者
			  
		数据一致（类似zookeeper的zap协议）：
			1.所有请求统一交予领导者角色完成，写入该对应的日志（对应zxid）并标志该状态为提交状态
			2.为了提交该日志，领导者角色就会将该日志以心跳的形式发送给其他跟随者，
			  只要满足过半的跟随者可以写入该数据，则为直接通知其他节点同步该数据（简称日志复制）
			3.超过时间之后，当前节点的状态可能由跟随者变为竞选者，会给其他节点发出选举的投票通知，只有
			  该竞选者超过半数以上即可选择领导者
				
	zookeeper基于zap协议实现保持每个节点数据同步问题，中心化思想集群模式
		中心化思想：
			根据muId/serverId（数值越大等级越大）或者根据随机时间（时间越短等级越大）配置区别哪个节点是主节点
			另一种情况：
				当开始集群的时候，已经选举了主节点的，后等级大的就只能是从节点了
			最终情况：
				当zookeeper的主节点的zxid事务id一致情况下，再去比较选择新的主节点（当主节点宕机）
				否则先比较zxid（数值越大等级越大）去选择新的主节点
		中心化思想缺陷：
			整个集群为了保证数据一致性，必须满足 n > n/2 + 1 才能实现集群环境
		数据同步：
			把每个节点请求的事务都交予主节点处理，再由主节点分发到各个从节点
2.分布式事务一致性
	核心解决在实际系统中产生的跨事务导致分布式事务问题
	核心在于最终一致性
	
	
	CAP原理
	
	
	
	
	
3.网关
	定义
		微服务网关是整个微服务api的请求入口，可以实现日志拦截、权限控制、解决跨域问题、限流、熔断、负载均衡、黑白名单拦截、授权等
	1.zuul与gateway的区别
		zuul属于netfix公司开源框架的第一代网关
		gateway属于springcloud的第二代网关
		注意：zuul底层基于servlet实现，阻塞式api，不支持长连接
			  springcloudgateway基于spring5构建，能够实现响应式非阻塞式api、
			  支持长连接、更好的支持spring体系产品、依赖springboot-webflux
	2.过滤器filter与gateway的区别
		filter支持单服务、gateway支持多服务
	3.动态网关
		1.分布式配置中心（json数组格式）阅读性差
		2.数据库表结构设计
			网关已经提供api接口
				1.直接新增
				2.直接修改
			加载时，网关从数据库读取配置并存到网关内存
			配置更新时，先更新数据库再调用
	4.词汇表
		1.route（路由）
			组成：id、URI（微服务真实路径）、匹配规则/谓词、过滤器filter
		2.谓词（匹配规则）
			weight（权重）：设置微服务在同一个group（分组）的情况下，gateway网关轮询按照百分比的概率（即不一定就是绝对的）分配路由
		3.filter（过滤器）
	5.工作原理（工作流）
		1.gateway client  
		2.dispatcherHandler
		3.gatewayHandlerMapper
		4.gatewayWebHandler
		5.一系列的filter
		6.最后执行代理服务proxyService
		
	
	
4.sentinel
	1.服务保护
		黑白名单、对ip实现限流/熔断机制、服务降级、服务隔离机制
	2.服务限流
		目的是为了保护服务。在高并发情况下，如果client的请求server达到一定的极限（设置阈值），请求数量超出我们的设置的阈值，
			开启我们的自我保护机制，直接执行我们的服务降级方法，不会执行我们的业务逻辑，走本地fallback方法。
	3.服务降级
		在高并发的情况下，为了防止用户一直等待，采用限流或熔断机制，保护我们的服务，不会执行我们的业务逻辑，走本地fallback方法。
		返回一个友好的提示给客户端。
	4.服务雪崩
		默认情况下，tomcat/jetty服务器只会有一个线程池处理所有接口的请求。
		这样的话，如果客户端所有请求都堆积在同一个接口上，那么久会产生该
		服务器的所有线程都在处理该接口，可能会导致其他接口无法访问，短暂没有线程的处理。
	5.服务隔离
		1.服务雪崩解决方案
		2.类别：线程池隔离/信号量隔离机制
			1.线程池隔离：每个接口都有自己独立的线程池维护我们的请求，每个线程池互不影响，
				缺点：占用服务器内存大。
			2.信号量隔离
				设置最多允许我们的某个接口有一定阈值的线程数量处理我们的接口，如果超出
				改线程数量，则拒绝访问。
		3.配置方案
			1.手动方式
				1.纯代码
				2.注解
			2.sentinel控制台方式
				默认情况下，sentinel不对数据持久化，需要自己独立持久化
		4.数据持久化
			1.zookeeper
			2.nacos
			3.阿波罗
			4.本地file
			思路：
				系统读取存放在nacos的sentinel的配置文件加载规则到内存，sentinel展示系统读取的nacos规则
		5.gateway整合sentinel实现限流
		6.服务降级
			先熔断，再降级
			策略
				1.rt（平均响应时间）
				2.错误比例
				3.错误次数
		7.基于sentinel实现热词限流
			
				
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	